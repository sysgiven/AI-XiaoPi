import json
import time
import asyncio
from core.utils import textUtils
from core.utils.util import audio_to_data
from core.providers.tts.dto.dto import SentenceType
from core.utils.audioRateController import AudioRateController

TAG = __name__


async def sendAudioMessage(conn, sentenceType, audios, text):
    if conn.tts.tts_audio_first_sentence:
        conn.logger.bind(tag=TAG).info(f"å‘é€ç¬¬ä¸€æ®µè¯­éŸ³: {text}")
        conn.tts.tts_audio_first_sentence = False
        await send_tts_message(conn, "start", None)

    if sentenceType == SentenceType.FIRST:
        # åŒä¸€å¥å­çš„åç»­æ¶ˆæ¯åŠ å…¥æµæ§é˜Ÿåˆ—ï¼Œå…¶ä»–æƒ…å†µç«‹å³å‘é€
        if (
            hasattr(conn, "audio_rate_controller")
            and conn.audio_rate_controller
            and getattr(conn, "audio_flow_control", {}).get("sentence_id")
            == conn.sentence_id
        ):
            conn.audio_rate_controller.add_message(
                lambda: send_tts_message(conn, "sentence_start", text)
            )
        else:
            # æ–°å¥å­æˆ–æµæ§å™¨æœªåˆå§‹åŒ–ï¼Œç«‹å³å‘é€
            await send_tts_message(conn, "sentence_start", text)

    await sendAudio(conn, audios)
    # å‘é€å¥å­å¼€å§‹æ¶ˆæ¯
    if sentenceType is not SentenceType.MIDDLE:
        conn.logger.bind(tag=TAG).debug(f"å‘é€éŸ³é¢‘æ¶ˆæ¯: {sentenceType}, {text}")

    # å‘é€ç»“æŸæ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯æœ€åä¸€ä¸ªæ–‡æœ¬ï¼‰
    if sentenceType == SentenceType.LAST:
        await send_tts_message(conn, "stop", None)
        conn.client_is_speaking = False
        if conn.close_after_chat:
            await conn.close()


async def _wait_for_audio_completion(conn):
    """
    ç­‰å¾…éŸ³é¢‘é˜Ÿåˆ—æ¸…ç©º

    Args:
        conn: è¿æ¥å¯¹è±¡
    """
    if hasattr(conn, "audio_rate_controller") and conn.audio_rate_controller:
        rate_controller = conn.audio_rate_controller
        conn.logger.bind(tag=TAG).debug(
            f"ç­‰å¾…éŸ³é¢‘å‘é€å®Œæˆï¼Œé˜Ÿåˆ—ä¸­è¿˜æœ‰ {len(rate_controller.queue)} ä¸ªåŒ…"
        )
        await rate_controller.queue_empty_event.wait()
        conn.logger.bind(tag=TAG).debug("éŸ³é¢‘å‘é€å®Œæˆ")


async def _send_to_mqtt_gateway(conn, opus_packet, timestamp, sequence):
    """
    å‘é€å¸¦16å­—èŠ‚å¤´éƒ¨çš„opusæ•°æ®åŒ…ç»™mqtt_gateway
    Args:
        conn: è¿æ¥å¯¹è±¡
        opus_packet: opusæ•°æ®åŒ…
        timestamp: æ—¶é—´æˆ³
        sequence: åºåˆ—å·
    """
    # ä¸ºopusæ•°æ®åŒ…æ·»åŠ 16å­—èŠ‚å¤´éƒ¨
    header = bytearray(16)
    header[0] = 1  # type
    header[2:4] = len(opus_packet).to_bytes(2, "big")  # payload length
    header[4:8] = sequence.to_bytes(4, "big")  # sequence
    header[8:12] = timestamp.to_bytes(4, "big")  # æ—¶é—´æˆ³
    header[12:16] = len(opus_packet).to_bytes(4, "big")  # opusé•¿åº¦

    # å‘é€åŒ…å«å¤´éƒ¨çš„å®Œæ•´æ•°æ®åŒ…
    complete_packet = bytes(header) + opus_packet
    await conn.websocket.send(complete_packet)


async def sendAudio(conn, audios, frame_duration=60):
    """
    å‘é€éŸ³é¢‘åŒ…ï¼Œä½¿ç”¨ AudioRateController è¿›è¡Œç²¾ç¡®çš„æµé‡æ§åˆ¶

    Args:
        conn: è¿æ¥å¯¹è±¡
        audios: å•ä¸ªopusåŒ…(bytes) æˆ– opusåŒ…åˆ—è¡¨
        frame_duration: å¸§æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤60ms
    """
    if audios is None or len(audios) == 0:
        return

    send_delay = conn.config.get("tts_audio_send_delay", -1) / 1000.0
    is_single_packet = isinstance(audios, bytes)

    # åˆå§‹åŒ–æˆ–è·å– RateController
    rate_controller, flow_control = _get_or_create_rate_controller(
        conn, frame_duration, is_single_packet
    )

    # ç»Ÿä¸€è½¬æ¢ä¸ºåˆ—è¡¨å¤„ç†
    audio_list = [audios] if is_single_packet else audios

    # å‘é€éŸ³é¢‘åŒ…
    await _send_audio_with_rate_control(
        conn, audio_list, rate_controller, flow_control, send_delay
    )


def _get_or_create_rate_controller(conn, frame_duration, is_single_packet):
    """
    è·å–æˆ–åˆ›å»º RateController å’Œ flow_control

    Args:
        conn: è¿æ¥å¯¹è±¡
        frame_duration: å¸§æ—¶é•¿
        is_single_packet: æ˜¯å¦å•åŒ…æ¨¡å¼ï¼ˆTrue: TTSæµå¼å•åŒ…, False: æ‰¹é‡åŒ…ï¼‰

    Returns:
        (rate_controller, flow_control)
    """
    # åˆ¤æ–­æ˜¯å¦éœ€è¦é‡ç½®ï¼šå•åŒ…æ¨¡å¼ä¸” sentence_id å˜åŒ–ï¼Œæˆ–è€…æ§åˆ¶å™¨ä¸å­˜åœ¨
    need_reset = (
        is_single_packet
        and getattr(conn, "audio_flow_control", {}).get("sentence_id")
        != conn.sentence_id
    ) or not hasattr(conn, "audio_rate_controller")

    # è¯Šæ–­æ—¥å¿—ï¼šä»…åœ¨éœ€è¦é‡ç½®æ—¶è¾“å‡ºï¼ˆè°ƒè¯•çº§åˆ«ï¼‰
    if need_reset:
        conn.logger.bind(tag=TAG).debug(
            f"Rate Controller é‡ç½®: current_sentence_id={conn.sentence_id}, "
            f"flow_control_sentence_id={getattr(conn, 'audio_flow_control', {}).get('sentence_id')}"
        )

    if need_reset:
        conn.logger.bind(tag=TAG).debug(f"ğŸ¬ å¯åŠ¨æ–°çš„Rate Controlleråå°ä»»åŠ¡ï¼ˆsentence_id={conn.sentence_id}ï¼‰")
        # åˆ›å»ºæˆ–è·å– rate_controller
        if not hasattr(conn, "audio_rate_controller"):
            conn.audio_rate_controller = AudioRateController(frame_duration)
            conn.logger.bind(tag=TAG).debug(f"   åˆ›å»ºæ–°çš„ AudioRateController")
        else:
            conn.logger.bind(tag=TAG).debug(f"   é‡ç½®ç°æœ‰çš„ AudioRateController")
            conn.audio_rate_controller.reset()

        # åˆå§‹åŒ– flow_control
        conn.audio_flow_control = {
            "packet_count": 0,
            "sequence": 0,
            "sentence_id": conn.sentence_id,
        }
        conn.logger.bind(tag=TAG).debug(f"   åˆå§‹åŒ– flow_control: sentence_id={conn.sentence_id}")

        # å¯åŠ¨åå°å‘é€å¾ªç¯
        _start_background_sender(
            conn, conn.audio_rate_controller, conn.audio_flow_control
        )
    else:
        conn.logger.bind(tag=TAG).debug(
            f"å¤ç”¨ç°æœ‰ Rate Controller (é˜Ÿåˆ—é•¿åº¦: {len(conn.audio_rate_controller.queue)}, "
            f"sentence_id={conn.sentence_id})"
        )

    return conn.audio_rate_controller, conn.audio_flow_control


def _start_background_sender(conn, rate_controller, flow_control):
    """
    å¯åŠ¨åå°å‘é€å¾ªç¯ä»»åŠ¡

    Args:
        conn: è¿æ¥å¯¹è±¡
        rate_controller: é€Ÿç‡æ§åˆ¶å™¨
        flow_control: æµæ§çŠ¶æ€
    """

    async def send_callback(packet):
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä¸­æ­¢
        if conn.client_abort:
            raise asyncio.CancelledError("å®¢æˆ·ç«¯å·²ä¸­æ­¢")

        conn.last_activity_time = time.time() * 1000
        await _do_send_audio(conn, packet, flow_control)
        conn.client_is_speaking = True

    # ä½¿ç”¨ start_sending å¯åŠ¨åå°å¾ªç¯
    task = rate_controller.start_sending(send_callback)


async def _send_audio_with_rate_control(
    conn, audio_list, rate_controller, flow_control, send_delay
):
    """
    ä½¿ç”¨ rate_controller å‘é€éŸ³é¢‘åŒ…

    Args:
        conn: è¿æ¥å¯¹è±¡
        audio_list: éŸ³é¢‘åŒ…åˆ—è¡¨
        rate_controller: é€Ÿç‡æ§åˆ¶å™¨
        flow_control: æµæ§çŠ¶æ€
        send_delay: å›ºå®šå»¶è¿Ÿï¼ˆç§’ï¼‰ï¼Œ-1è¡¨ç¤ºä½¿ç”¨åŠ¨æ€æµæ§
    """
    pre_buffer_count = 5

    for packet in audio_list:
        if conn.client_abort:
            return

        conn.last_activity_time = time.time() * 1000

        # é¢„ç¼“å†²ï¼šå‰5ä¸ªåŒ…ç›´æ¥å‘é€
        if flow_control["packet_count"] < pre_buffer_count:
            conn.logger.bind(tag=TAG).debug(f"é¢„ç¼“å†²å‘é€ #{flow_control['packet_count']+1}")
            await _do_send_audio(conn, packet, flow_control)
            conn.client_is_speaking = True
        elif send_delay > 0:
            # å›ºå®šå»¶è¿Ÿæ¨¡å¼
            conn.logger.bind(tag=TAG).debug(f"å›ºå®šå»¶è¿Ÿå‘é€ #{flow_control['packet_count']+1}")
            await asyncio.sleep(send_delay)
            await _do_send_audio(conn, packet, flow_control)
            conn.client_is_speaking = True
        else:
            # åŠ¨æ€æµæ§æ¨¡å¼ï¼šä»…æ·»åŠ åˆ°é˜Ÿåˆ—ï¼Œç”±åå°å¾ªç¯è´Ÿè´£å‘é€
            conn.logger.bind(tag=TAG).debug(f"æ·»åŠ åˆ°é˜Ÿåˆ— #{flow_control['packet_count']+1}")
            rate_controller.add_audio(packet)


async def _do_send_audio(conn, opus_packet, flow_control):
    """
    æ‰§è¡Œå®é™…çš„éŸ³é¢‘å‘é€
    """
    packet_index = flow_control.get("packet_count", 0)
    sequence = flow_control.get("sequence", 0)

    if conn.conn_from_mqtt_gateway:
        # è®¡ç®—æ—¶é—´æˆ³ï¼ˆåŸºäºæ’­æ”¾ä½ç½®ï¼‰
        start_time = time.time()
        timestamp = int(start_time * 1000) % (2**32)
        await _send_to_mqtt_gateway(conn, opus_packet, timestamp, sequence)
    else:
        # ç›´æ¥å‘é€opusæ•°æ®åŒ…
        await conn.websocket.send(opus_packet)

    # æ›´æ–°æµæ§çŠ¶æ€
    flow_control["packet_count"] = packet_index + 1
    flow_control["sequence"] = sequence + 1


async def send_tts_message(conn, state, text=None):
    """å‘é€ TTS çŠ¶æ€æ¶ˆæ¯"""
    if text is None and state == "sentence_start":
        return
    message = {"type": "tts", "state": state, "session_id": conn.session_id}
    if text is not None:
        message["text"] = textUtils.check_emoji(text)

    # TTSæ’­æ”¾ç»“æŸ
    if state == "stop":
        # æ’­æ”¾æç¤ºéŸ³
        tts_notify = conn.config.get("enable_stop_tts_notify", False)
        if tts_notify:
            stop_tts_notify_voice = conn.config.get(
                "stop_tts_notify_voice", "config/assets/tts_notify.mp3"
            )
            audios = await audio_to_data(stop_tts_notify_voice, is_opus=True)
            await sendAudio(conn, audios)
        # ç­‰å¾…æ‰€æœ‰éŸ³é¢‘åŒ…å‘é€å®Œæˆ
        await _wait_for_audio_completion(conn)
        # æ¸…é™¤æœåŠ¡ç«¯è®²è¯çŠ¶æ€
        conn.clearSpeakStatus()

    # å‘é€æ¶ˆæ¯åˆ°å®¢æˆ·ç«¯
    await conn.websocket.send(json.dumps(message))


async def send_stt_message(conn, text):
    """å‘é€ STT çŠ¶æ€æ¶ˆæ¯"""
    end_prompt_str = conn.config.get("end_prompt", {}).get("prompt")
    if end_prompt_str and end_prompt_str == text:
        await send_tts_message(conn, "start")
        return

    # è§£æJSONæ ¼å¼ï¼Œæå–å®é™…çš„ç”¨æˆ·è¯´è¯å†…å®¹
    display_text = text
    try:
        # å°è¯•è§£æJSONæ ¼å¼
        if text.strip().startswith("{") and text.strip().endswith("}"):
            parsed_data = json.loads(text)
            if isinstance(parsed_data, dict) and "content" in parsed_data:
                # å¦‚æœæ˜¯åŒ…å«è¯´è¯äººä¿¡æ¯çš„JSONæ ¼å¼ï¼Œåªæ˜¾ç¤ºcontentéƒ¨åˆ†
                display_text = parsed_data["content"]
                # ä¿å­˜è¯´è¯äººä¿¡æ¯åˆ°connå¯¹è±¡
                if "speaker" in parsed_data:
                    conn.current_speaker = parsed_data["speaker"]
    except (json.JSONDecodeError, TypeError):
        # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡æœ¬
        display_text = text
    stt_text = textUtils.get_string_no_punctuation_or_emoji(display_text)
    await conn.websocket.send(
        json.dumps({"type": "stt", "text": stt_text, "session_id": conn.session_id})
    )
    await send_tts_message(conn, "start")
